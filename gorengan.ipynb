{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOk4gTvy/OatFeUKOe0Hoku",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asigen93/DeepLearning_Tugas2/blob/main/gorengan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "RlkONubvrf_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8v3uVG6nmDAW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, datasets, models\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "wSvKizJprr5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "39SDBzq5reiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb404840-3add-4103-fd45-84ed6b76910d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Transform Data"
      ],
      "metadata": {
        "id": "yX8ChX6p8dyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Ganti path sesuai lokasi dataset kamu di Google Drive\n",
        "data_dir = \"/content/drive/MyDrive/Deep Learning (Gorengan)\"\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)"
      ],
      "metadata": {
        "id": "PDuNDsd77-E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Placing Data into a DataFrame"
      ],
      "metadata": {
        "id": "SnKv_0sI-4IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = [path[0] for path in dataset.imgs]\n",
        "labels = [path[1] for path in dataset.imgs]\n",
        "class_names = dataset.classes\n",
        "\n",
        "df = pd.DataFrame({\"Image Path\": image_paths, \"Label\": labels})\n",
        "df[\"Label Name\"] = df[\"Label\"].apply(lambda x: class_names[x])\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "kVi6K4Gb8e3V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "3931c4de-95c7-4d61-9d7f-38f8279fed7e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3cc20745a417>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Image Path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing images from the dataset"
      ],
      "metadata": {
        "id": "ExKt8Xkd-7X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample_images(dataset, class_names):\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    for i, cls in enumerate(class_names):\n",
        "        idx = dataset.class_to_idx[cls]\n",
        "        img_path, _ = dataset.imgs[np.where(np.array(labels)==idx)[0][0]]\n",
        "        image = Image.open(img_path)\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(cls)\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    show_sample_images(dataset, class_names)"
      ],
      "metadata": {
        "id": "DXN1euek--x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error Rate Function"
      ],
      "metadata": {
        "id": "a4_i2kJF_Hcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_error_rate(y_true, y_pred):\n",
        "    return 1 - np.mean(np.array(y_true) == np.array(y_pred))"
      ],
      "metadata": {
        "id": "DfrkRnaC_MrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "NqiBO2Hs_O-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "oLSLCkXx_S8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load EfficientNet-B0"
      ],
      "metadata": {
        "id": "Q3yZ2wWd_T4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = models.efficientnet_b0(pretrained=True)\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "LCPqT0aS_Wk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "kVdOwTtZ_aW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch}/50, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {acc:.2f}%\")"
      ],
      "metadata": {
        "id": "m31q7iu8_c14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing Loss Curves"
      ],
      "metadata": {
        "id": "80jtbTeK_hs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.title(\"Loss Curves\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bmZBWRnW_jqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "KNqK9-xj_m5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X8Q6trO3_n4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making predictions on the Test Data"
      ],
      "metadata": {
        "id": "oOVjQaDo_pjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path, model, transform, class_names):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        _, prediction = torch.max(output, 1)\n",
        "    return class_names[prediction.item()]\n",
        "\n",
        "print(\"Prediction:\", predict_image(df[\"Image Path\"].iloc[10], model, transform, class_names))"
      ],
      "metadata": {
        "id": "qbj1eWcE_v1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad-CAM Visualization"
      ],
      "metadata": {
        "id": "4I9MSFvl_yq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_cam(model, image_path, class_idx=None):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    features_blobs = []\n",
        "\n",
        "    def hook_feature(module, input, output):\n",
        "        features_blobs.append(output)\n",
        "\n",
        "    handle = model.features[-1].register_forward_hook(hook_feature)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_tensor)\n",
        "        pred_idx = output.argmax(dim=1).item() if class_idx is None else class_idx\n",
        "        score = output[0, pred_idx]\n",
        "\n",
        "    model.zero_grad()\n",
        "    score.backward(retain_graph=True)\n",
        "\n",
        "    gradients = model.features[-1][0].weight.grad\n",
        "    activations = features_blobs[0].squeeze(0)\n",
        "\n",
        "    weights = torch.mean(gradients, dim=[1, 2])\n",
        "    cam = torch.zeros(activations.shape[1:], dtype=torch.float32)\n",
        "\n",
        "    for i, w in enumerate(weights):\n",
        "        cam += w * activations[i]\n",
        "\n",
        "    cam = torch.clamp(cam, min=0).cpu().numpy()\n",
        "    cam = cv2.resize(cam, (224, 224))\n",
        "    cam -= np.min(cam)\n",
        "    cam /= np.max(cam)\n",
        "\n",
        "    img = cv2.cvtColor(np.array(image.resize((224,224))), cv2.COLOR_RGB2BGR)\n",
        "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "    superimposed = heatmap * 0.4 + img\n",
        "\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(superimposed[...,::-1].astype(np.uint8))\n",
        "    plt.title(\"Grad-CAM\")\n",
        "    plt.show()\n",
        "\n",
        "    handle.remove()\n",
        "\n",
        "# Contoh penggunaan Grad-CAM\n",
        "grad_cam(model, df[\"Image Path\"].iloc[10])"
      ],
      "metadata": {
        "id": "YEJiBC26Aot8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}